{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import google.cloud.aiplatform as aip\n",
    "# from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "import kfp\n",
    "from kfp import dsl\n",
    "from kfp.v2 import compiler\n",
    "from kfp.v2.dsl import component\n",
    "import json\n",
    "from kfp.v2.google.client import AIPlatformClient\n",
    "from kfp.v2.dsl import (Artifact,\n",
    "                        ClassificationMetrics, \n",
    "                        component,\n",
    "                        Dataset,\n",
    "                        Input,\n",
    "                        Metrics,\n",
    "                        Model,\n",
    "                        Output\n",
    "                       )\n",
    "from typing import NamedTuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project ID \n",
    "Val = !gcloud config list --format 'value(core.project)'\n",
    "PROJECT_ID = Val[0]\n",
    "REGION = \"us-west1\"\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "SERVICE_ACCOUNT = \"559647087083-compute@developer.gserviceaccount.com\"\n",
    "BUCKET_NAME = \"gs://demo-account\"\n",
    "PIPELINE_ROOT = \"{}/pipeline_root/\".format(BUCKET_NAME)\n",
    "PIPELINE_JSON_FILE = \"final.json\"\n",
    "PIPELINE_EXPERIMENT_NAME = \"mainscoringpipeline\" + TIMESTAMP\n",
    "MODEL_DISPLAY_NAME = \"main-model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aip.init(project=PROJECT_ID, location=REGION,staging_bucket=BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(base_image=\"gcr.io/ml-pipeline/google-cloud-pipeline-components:latest\",\n",
    "           packages_to_install = [\"pandas\"],          \n",
    "          )\n",
    "def bq_load() -> str:\n",
    "    return \"Hello\"\n",
    "#     from google.cloud import bigquery\n",
    "#     client = bigquery.Client(location=\"US\", project='hackteam-mythbusters1')\n",
    "    \n",
    "#     query = \"\"\"\n",
    "#     SELECT * FROM `hackteam-mythbusters1.covid_dataset.combined1`\n",
    "#     \"\"\"\n",
    "#     query_job = client.query(\n",
    "#         query,\n",
    "#         location=\"US\",\n",
    "#     )\n",
    "\n",
    "#     df = query_job.to_dataframe()\n",
    "#     df.to_csv(train_data.path, index=False)\n",
    "#     return(train_data.path.replace(\"/gcs/\", \"gs://\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(base_image=\"gcr.io/ml-pipeline/google-cloud-pipeline-components:latest\", packages_to_install=['google-cloud-aiplatform'],)\n",
    "def import_model(\n",
    "    project_id: str,\n",
    "    display_name: str,\n",
    "    artifact_gcs_bucket: str,\n",
    "    model: Output[Model],\n",
    "    location: str,\n",
    "    serving_container_image_uri: str,\n",
    "    description: str\n",
    ") -> NamedTuple(\n",
    "    'Outputs', \n",
    "    [ \n",
    "        ('display_name', str), \n",
    "        ('resource_name', str)\n",
    "    ]\n",
    "):\n",
    "    from google.cloud import aiplatform\n",
    "    aiplatform.init(project=project_id, location=location)\n",
    "    model_resp = aiplatform.Model.upload(\n",
    "        display_name=display_name,\n",
    "        artifact_uri=artifact_gcs_bucket,\n",
    "        serving_container_image_uri=serving_container_image_uri,\n",
    "        description=description)\n",
    "    model_resp.wait()\n",
    "    with open(model.path, 'w') as f: \n",
    "      f.write(model_resp.resource_name)\n",
    "    model.path = f\"aiplatform://v1/{model_resp.resource_name}\" #update the resource path to aiplaform://v1 prefix so that off the shelf tasks can consume the output\n",
    "    return (model_resp.display_name, model_resp.resource_name,)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    name=PIPELINE_EXPERIMENT_NAME,\n",
    ")\n",
    "def pipeline(\n",
    "    project: str = PROJECT_ID,\n",
    "    region:str = REGION,\n",
    "):\n",
    "    dataset_op = bq_load()\n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.v2 import compiler  # noqa: F811\n",
    "\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline, package_path=PIPELINE_JSON_FILE\n",
    ")\n",
    "\n",
    "\n",
    "job = aip.PipelineJob(\n",
    "    display_name=PIPELINE_EXPERIMENT_NAME,\n",
    "    template_path=PIPELINE_JSON_FILE,\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    parameter_values={\"project\":PROJECT_ID,\"region\":REGION},\n",
    ")\n",
    "\n",
    "job.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.v2.google.client import AIPlatformClient  # noqa: F811\n",
    "\n",
    "api_client = AIPlatformClient(project_id=PROJECT_ID, region=REGION)\n",
    "\n",
    "# adjust time zone and cron schedule as necessary\n",
    "response = api_client.create_schedule_from_job_spec(\n",
    "    job_spec_path=PIPELINE_JSON_FILE,\n",
    "    schedule=\"0 6 1 * *\",\n",
    "    time_zone=\"America/Los_Angeles\",  # change this as necessary\n",
    "    pipeline_root=PIPELINE_ROOT  # this argument is necessary if you did not specify PIPELINE_ROOT as part of the pipeline definition.\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
